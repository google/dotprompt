{"traceId":"cb9a4c8b483f87e54603838b1dad4427","spans":{"ff548ff271743062":{"spanId":"ff548ff271743062","traceId":"cb9a4c8b483f87e54603838b1dad4427","startTime":1740766011571,"endTime":1740766014549.2598,"attributes":{"genkit:type":"action","genkit:metadata:subtype":"model","genkit:name":"googleai/gemini-2.0-flash","genkit:isRoot":true,"genkit:path":"/{googleai/gemini-2.0-flash,t:action}","genkit:input":"{\"messages\":[{\"role\":\"user\",\"content\":[{\"text\":\"You are assisting a user on Prompt Fiddle, a web app that allows users to create and share LLM prompts. Your task is to generate or revise a prompt based on the request from the user.\\n\\nYou will be provided both with a guide on general prompting techniques and specific reference documentation for Dotprompt. When generating the prompt:\\n\\n- Think about what variables, if any, would be appropriate to accept as `input`.\\n- Think about the output format. If structured data would be appropriate, use the `output` configuration to provide a schema.\\n- The output schema in a Dotprompt template is automatically added to the instructions, you don't need to \\\"double-describe\\\" the output.\\n- Make sure to include descriptions for each field if there is an output schema. For arrays of scalars, prefer to describe the field at the array level, not the item level.\\n- The prompting docs are a generic guide not specific to Dotprompt. Prefer Dotprompt documentation if there are disagreements.\\n- Unless the prompt is explicitly conversational, prefer a single user message prompt instead of using a system message.\\n\\n=== User's Prompt Request ===\\n\\na prompt to generate a delicious recipe with ingredients, steps, etc.\\n\\n\\n=== LLM Prompting Guidance ===\\n\\nThis page introduces you to some general prompt design strategies that you can employ when designing prompts.\\n\\nLarge language models (LLM) are trained on vast amounts of text data to learn the patterns and relationships between language. When given some text (the prompt), language models can predict what is likely to come next, like a sophisticated autocompletion tool.\\n\\nGoogle AI Studio hosts a simple [prompt gallery](https://aistudio.google.com/app/gallery) meant to interactively showcase many of the concepts shared in this guide. In the rest of this guide, you'll learn about the following prompt design strategies:\\n\\n## Give clear and specific instructions\\n\\nGiving the model instructions on what to do is an effective and efficient way to customize model behavior. Ensure that the instructions you give are clear and specific. Instructions can be as simple as a list of step-by-step instructions or as complex as mapping out a user's experience and mindset.\\n\\n### Define the task to perform\\n\\nDescribe in detail the task that you want the model to perform. The task can be as simple as a step-by-step list of instructions or as complex as mapping out a user's experience and mindset. The following prompt tells the model to summarize a block of text:\\n\\n**Prompt:**\\n\\n**Summarize this text:**\\nText: A quantum computer exploits quantum mechanical phenomena to perform calculations exponentially\\nfaster than any modern traditional computer. At very tiny scales, physical matter acts as both\\nparticles and as waves, and quantum computing uses specialized hardware to leverage this behavior.\\nThe operating principles of quantum devices is beyond the scope of classical physics. When deployed\\nat scale, quantum computers could be used in a wide variety of applications such as: in\\ncybersecurity to break existing encryption methods while helping researchers create new ones, in\\nmeteorology to develop better weather forecasting etc. However, the current state of the art quantum\\ncomputers are still largely experimental and impractical.\\n  \\n\\n**Response:**\\n\\n    Quantum computers leverage the wave-particle duality of matter at tiny scales to perform\\n    calculations exponentially faster than traditional computers. They harness quantum phenomena,\\n    which are beyond the scope of classical physics, to achieve this speed advantage. While\\n    promising for applications like cybersecurity, weather forecasting, and beyond, current\\n    quantum computers are still experimental and not yet practical for widespread use.\\n  \\n### Specify any constraints\\n\\nSpecify any constraints on reading the prompt or generating a response. You can tell the model what to do and not to do. From the previous example, the summarization is shorter than the original text, but maybe you want the summary to be shorter. In this case, you can specify a constraint in the prompt on how long you want the summary to be:\\n\\n**Prompt:**\\n\\n**Summarize this text in two sentences:**\\nText: A quantum computer exploits quantum mechanical phenomena to perform calculations exponentially\\nfaster than any modern traditional computer. At very tiny scales, physical matter acts as both\\nparticles and as waves, and quantum computing uses specialized hardware to leverage this behavior.\\nThe operating principles of quantum devices is beyond the scope of classical physics. When deployed\\nat scale, quantum computers could be used in a wide variety of applications such as: in\\ncybersecurity to break existing encryption methods while helping researchers create new ones, in\\nmeteorology to develop better weather forecasting etc. However, the current state of the art quantum\\ncomputers are still largely experimental and impractical.\\n    \\n\\n**Response:**\\n\\n      Quantum computers harness the wave-particle duality of matter at the quantum level to perform\\n      computations exponentially faster than traditional computers. While these machines hold\\n      immense potential for fields like cybersecurity and weather forecasting, they are currently\\n      in their early stages of development and not yet practical for widespread use.\\n    \\n\\n### Define the format of the response\\n\\nYou can also give instructions that specify the format of the response. For example, you can ask for the response to be formatted as a table, bulleted list, elevator pitch, keywords, sentence, or paragraph. The following system message instructs the model to be more conversational in its response:\\n\\n**System message**\\n\\n    All questions should be answered comprehensively with details, unless the user requests a concise response specifically.\\n\\n**Prompt**\\n\\n    What is a smart way to make a business that sells DVD's in 2025?\\n  \\n**Response:**\\n\\n    Okay, you're looking at a real uphill battle here. The DVD market is significantly diminished due to streaming services, digital downloads, and Blu-ray. However, that doesn't necessarily mean it's impossible to build a DVD-based business in 2025. It just requires a hyper-focused strategy and a deep understanding of the remaining market. Here's a breakdown of smart approaches:\\n\\n    I. Understanding the Challenges and Opportunities\\n    Challenges:\\n    Dominance of Streaming: Netflix, Amazon Prime Video, Disney+, and countless other services offer vast libraries on-demand.\\n    Digital Downloads/Rentals: Platforms like iTunes, Google Play, and Vudu make purchasing or renting digital versions easy.\\n    Blu-ray & 4K Ultra HD: Offer superior picture and sound quality, often preferred by home theater enthusiasts.\\n\\nAnother example which we used in the past is:\\n\\n**System message**\\n\\n      All questions should be answered comprehensively with details, unless the user requests a\\n      concise response specifically. Respond in the same language as the query.\\n  \\n**Prompt**\\n\\n      What is a smart way to create a lemonade business?\\n    \\n**Response:**\\n\\n  Launching a Successful Lemonade Stand: A Smart Approach\\n  Creating a lemonade business, whether a simple stand or a larger operation, requires strategic thinking. Here's a breakdown of how to approach it smartly:\\n  \\n  1. Define Your Business:\\n  Scope: Are you aiming for a small, seasonal lemonade stand, a food truck, a delivery service, or something else entirely?\\n  Target Audience: Who are you selling to? Families, office workers, tourists?\\n  Unique Selling Proposition: What sets your lemonade apart? Special flavors, organic ingredients, a unique recipe?\\n  \\n  Pricing: Research competitor prices and determine a profitable pricing structure.\\n  Location: Consider foot traffic, accessibility, and regulations for your chosen location.\\n  .....\\n    \\n### Summary\\n\\n*   Give the models instructions on what to do.\\n*   Make the instructions clear and specific.\\n*   Specify any constraints or formatting requirements for the output.\\n\\n## Include few-shot examples\\n\\nYou can include examples in the prompt that show the model what getting it right looks like. The model attempts to identify patterns and relationships from the examples and applies them when generating a response. Prompts that contain a few examples are called _few-shot_ prompts, while prompts that provide no examples are called _zero-shot prompts_. Few-shot prompts are often used to regulate the formatting, phrasing, scoping, or general patterning of model responses. Use specific and varied examples to help the model narrow its focus and generate more accurate results.\\n\\nWe recommend to always include few-shot examples in your prompts. Prompts without few-shot examples are likely to be less effective. In fact, you can remove instructions from your prompt if your examples are clear enough in showing the task at hand.\\n\\n### Zero-shot vs few-shot prompts\\n\\nThe following zero-shot prompt asks the model to choose the best explanation.\\n\\n**Prompt:**\\n\\nPlease choose the best explanation to the question:\\n\\nQuestion: How is snow formed?\\nExplanation1: Snow is formed when water vapor in the air freezes into ice crystals in the\\natmosphere, which can combine and grow into snowflakes as they fall through the atmosphere and\\naccumulate on the ground.\\nExplanation2: Water vapor freezes into ice crystals forming snow.\\nAnswer:\\n  \\n\\n**Response:**\\n\\nExplanation 1 is the best explanation.\\n\\nIf your use case requires the model to produce concise responses, you can include examples in the prompt that give preference to concise responses.\\n\\nThe following prompt provides two examples that show preference to the shorter explanations. In the response, you can see that the examples guided the model to choose the shorter explanation (Explanation2) as opposed to the longer explanation (Explanation1) like it did previously.\\n\\n**Prompt:**\\n\\nBelow are some examples showing a question, explanation, and answer format:\\n\\nQuestion: Why is sky blue?\\nExplanation1: The sky appears blue because of Rayleigh scattering, which causes shorter blue\\nwavelengths of light to be scattered more easily than longer red wavelengths, making the sky look\\nblue.\\nExplanation2: Due to Rayleigh scattering effect.\\nAnswer: Explanation2\\n\\nQuestion: What is the cause of earthquakes?\\nExplanation1: Sudden release of energy in the Earth's crust.\\nExplanation2: Earthquakes happen when tectonic plates suddenly slip or break apart, causing a\\nrelease of energy that creates seismic waves that can shake the ground and cause damage.\\nAnswer: Explanation1\\n\\nNow, Answer the following question given the example formats above:\\n\\nQuestion: How is snow formed?\\nExplanation1: Snow is formed when water vapor in the air freezes into ice crystals in the\\natmosphere, which can combine and grow into snowflakes as they fall through the atmosphere and\\naccumulate on the ground.\\nExplanation2: Water vapor freezes into ice crystals forming snow.\\nAnswer:\\n  \\n**Response:**\\n\\nAnswer: Explanation2\\n  \\n### Find the optimal number of examples\\n\\nYou can experiment with the number of examples to provide in the prompt for the most desired results. Models like Gemini can often pick up on patterns using a few examples, though you may need to experiment with what number of examples lead to the desired results. At the same time, if you include too many examples, the model may start to [overfit](https://developers.google.com/machine-learning/glossary#overfitting) the response to the examples.\\n\\n### Use examples to show patterns instead of antipatterns\\n\\nUsing examples to show the model a pattern to follow is more effective than using examples to show the model an antipattern to avoid.\\n\\n⛔ **Negative pattern**:\\n\\n**Example**\\n\\nDon't end haikus with a question:\\nHaiku are fun\\nA short and simple poem\\nDon't you enjoy them?\\n  \\n✅ **Positive pattern**:\\n\\n**Example**\\n\\nAlways end haikus with an assertion:\\nHaiku are fun\\nA short and simple poem\\nA joy to write\\n  \\n### Use consistent formatting across examples\\n\\nMake sure that the structure and formatting of few-shot examples are the same to avoid responses with undesired formats. One of the primary objectives of adding few-shot examples in prompts is to show the model the response format. Therefore, it is essential to ensure a consistent format across all examples, especially paying attention to XML tags, white spaces, newlines, and example splitters.\\n\\n### Summary\\n\\n*   Including prompt-response examples in the prompt helps the model learn how to respond.\\n*   Give the model examples of the patterns to follow instead of examples of patterns to avoid.\\n*   Experiment with the number of prompts to include. Depending on the model, too few examples are ineffective at changing model behavior. Too many examples cause the model to overfit.\\n*   Use consistent formatting across examples\\n\\n## Add contextual information\\n\\nYou can include in the prompt instructions and information that the model needs to solve a problem instead of assuming that the model has all of the required information. This contextual information helps the model understand the constraints and details of what you're asking for it to do.\\n\\nThe following example asks the model to give troubleshooting guidance for a router:\\n\\n**Prompt:**\\n\\nWhat should I do to fix my disconnected wifi? **The light on my Google Wifi router is yellow and\\nblinking slowly.**\\n  \\n**Response:**\\n\\n  A yellow blinking light on your Google Wifi router usually indicates a problem with the internet connection. Here are some steps to troubleshoot and fix the issue:\\n  1. Restart your router and modem:\\n    - Unplug your modem from the power outlet and wait for 30 seconds.\\n    - Plug your modem back in and wait for it to fully boot up.\\n    - Unplug your Google Wifi router and wait for 30 seconds.\\n    - Plug your Google Wifi router back in and wait for it to fully boot up.\\n\\nThe response looks like generic troubleshooting information that's not specific to the router or the status of the LED indicator lights.\\n\\nTo customize the response for the specific router, you can add to the prompt the router's troubleshooting guide as context for it to refer to when providing a response.\\n\\n**Prompt:**\\n\\nAnswer the question using the text below. Respond with only the text provided.\\nQuestion: What should I do to fix my disconnected wifi? The light on my Google Wifi router is yellow and blinking slowly.\\n\\nText:\\nColor: Slowly pulsing yellow\\nWhat it means: There is a network error.\\nWhat to do:\\nCheck that the Ethernet cable is connected to both your router and your modem and both devices are turned on. You might need to unplug and plug in each device again.\\n\\nColor: Fast blinking yellow\\nWhat it means: You are holding down the reset button and are factory resetting this device.\\nWhat to do:\\nIf you keep holding down the reset button, after about 12 seconds, the light will turn solid yellow. Once it is solid yellow, let go of the factory reset button.\\n\\nColor: Solid yellow\\nWhat it means: Router is factory resetting.\\nWhat to do:\\nThis can take up to 10 minutes. When it's done, the device will reset itself and start pulsing white, letting you know it's ready for setup.\\n\\nColor: Solid red\\nWhat it means: Something is wrong.\\nWhat to do:\\nCritical failure. Factory reset the router. If the light stays red, contact Wifi customer support.\\n  \\n**Response:**\\n\\nCheck that the Ethernet cable is connected to both your router and your modem and both devices are turned on. You might need to unplug and plug in each device again.\\n  \\n### Summary\\n\\n*   Include information (context) in the prompt that you want the model to use when generating a response.\\n*   Give the model instructions on how to use the contextual information.\\n\\nAdd prefixes\\n------------\\n\\nA prefix is a word or phrase that you add to the prompt content that can serve several purposes, depending on where you put the prefix:\\n\\n*   **Input prefix:** Adding a prefix to the input signals semantically meaningful parts of the input to the model. For example, the prefixes \\\"English:\\\" and \\\"French:\\\" demarcate two different languages.\\n*   **Output prefix:** Even though the output is generated by the model, you can add a prefix for the output in the prompt. The output prefix gives the model information about what's expected as a response. For example, the output prefix \\\"JSON:\\\" signals to the model that the output should be in JSON format.\\n*   **Example prefix:** In few-shot prompts, adding prefixes to the examples provides labels that the model can use when generating the output, which makes it easier to parse output content.\\n\\nIn the following example, \\\"Text:\\\" is the input prefix and \\\"The answer is:\\\" is the output prefix.\\n\\n**Prompt:**\\n\\nClassify the text as one of the following categories.\\n- large\\n- small\\nText: Rhino\\nThe answer is: large\\nText: Mouse\\nThe answer is: small\\nText: Snail\\nThe answer is: small\\nText: Elephant\\nThe answer is:\\n  \\n\\n**Response:**\\n\\nThe answer is: large\\n  \\n## Let the model complete partial input\\n\\nGenerative language models work like an advanced autocompletion tool. When you provide partial content, the model can provide the rest of the content or what it thinks is a continuation of that content as a response. When doing so, if you include any examples or context, the model can take those examples or context into account.\\n\\nThe following example provides a prompt with an instruction and an entity input:\\n\\n**Prompt:**\\n\\nFor the given order, return a JSON object that has the fields cheeseburger, hamburger, fries, or\\ndrink, with the value being the quantity.\\n\\nOrder: A burger and a drink.\\n  \\n**Response:**\\n\\n\\\\`\\\\`\\\\`\\n{\\n  \\\"hamburger\\\": 1,\\n  \\\"drink\\\": 1\\n}\\n\\\\`\\\\`\\\\`\\n  \\n\\n(gemini-1.5-flash)\\n\\nWhile the model did as prompted, writing out the instructions in natural language can sometimes be challenging and it leaves a lot to the model's interpretation. For example, a restaurants menu might contain many items. To reduce the size of the JSON response, you probably want to omit the items that weren't ordered. In this case, you can give an example and a response prefix and let the model complete it:\\n\\n**Prompt:**\\n\\nValid fields are cheeseburger, hamburger, fries, and drink.\\nOrder: Give me a cheeseburger and fries\\nOutput:\\n\\\\`\\\\`\\\\`\\n{\\n  \\\"cheeseburger\\\": 1,\\n  \\\"fries\\\": 1\\n}\\n\\\\`\\\\`\\\\`\\nOrder: I want two burgers, a drink, and fries.\\nOutput:\\n  \\n**Response:**\\n\\n\\\\`\\\\`\\\\`\\n{\\n  \\\"hamburger\\\": 2,\\n  \\\"drink\\\": 1,\\n  \\\"fries\\\": 1\\n}\\n\\\\`\\\\`\\\\`\\n  \\nNotice how \\\"cheeseburger\\\" was excluded from the output because it wasn't a part of the order.\\n\\n#### Prompt the model to format its response\\n\\nThe completion strategy can also help format the response. The following example prompts the model to create an essay outline:\\n\\n**Prompt:**\\n\\nCreate an outline for an essay about hummingbirds.\\n  \\n**Response:**\\n\\n  Hummingbirds: A Symphony of Speed and Color\\n    I. Introduction\\n    A. Hummingbirds are fascinating creatures known for their dazzling colors, lightning-fast flight, and unique feeding habits.\\n    B. Brief overview of the diversity of hummingbird species and their geographic distribution.\\n    C. Thesis statement: Hummingbirds are an embodiment of resilience, adaptation, and the wonders of the natural world.\\n\\nThe prompt didn't specify the format for the outline and the model chose a format for you. To get the model to return an outline in a specific format, you can add text that represents the start of the outline and let the model complete it based on the pattern that you initiated.\\n\\n**Prompt:**\\n\\nCreate an outline for an essay about hummingbirds.\\nI. Introduction\\n   \\\\*\\n  \\n\\n**Response:**\\n\\n  Hummingbirds: Jewels of the Air\\n    \\\\*\\\\*I. Introduction\\\\*\\\\*\\n       \\\\* \\\\*\\\\*Hook:\\\\*\\\\* Begin with a captivating image or anecdote about hummingbirds, emphasizing their vibrant colors, rapid flight, and unique feeding habits.\\n       \\\\* \\\\*\\\\*Background:\\\\*\\\\* Briefly introduce hummingbirds as the smallest birds in the world and their fascinating adaptations for a nectar-rich diet.\\n       \\\\* \\\\*\\\\*Thesis:\\\\*\\\\* State the main argument or focus of the essay. Examples: \\n            \\\\* \\\\*\\\\*The incredible adaptations of hummingbirds enable them to thrive in diverse ecosystems.\\\\*\\\\*\\n            \\\\* \\\\*\\\\*Hummingbirds play a crucial role in pollination and biodiversity.\\\\*\\\\*\\n            \\\\* \\\\*\\\\*The beauty and grace of hummingbirds make them captivating subjects for both scientific study and artistic appreciation.\\\\*\\\\*\\n  \\n### Summary\\n\\n*   If you give the model a partial input, the model completes that input based on any available examples or context in the prompt.\\n*   Having the model complete an input may sometimes be easier than describing the task in natural language.\\n*   Adding a partial answer to a prompt can guide the model to follow a desired pattern or format.\\n\\n## Break down prompts into simple components\\n\\nFor use cases that require complex prompts, you can help the model manage this complexity by breaking things down into simpler components.\\n\\n### Break down instructions\\n\\nInstead of having many instructions in one prompt, create one prompt per instruction. You can choose which prompt to process based on the user's input.\\n\\n### Chain prompts\\n\\nFor complex tasks that involve multiple sequential steps, make each step a prompt and chain the prompts together in a sequence. In this sequential chain of prompts, the output of one prompt in the sequence becomes the input of the next prompt. The output of the last prompt in the sequence is the final output.\\n\\n### Aggregate responses\\n\\nAggregation is when you want to perform different parallel tasks on different portions of the data and aggregate the results to produce the final output. For example, you can tell the model to perform one operation on the first part of the data, perform another operation on the rest of the data and aggregate the results.\\n\\n### Summary\\n\\n*   Break down complex instructions into a prompt for each instruction and decide which prompt to apply based on the user's input.\\n*   Break down multiple sequential steps into separate prompts and chain them such that the output on the preceding prompt becomes the input of the following prompt.\\n*   Break down parallel tasks and aggregate the responses to produce the final output.\\n\\n## Experiment with different parameter values\\n\\nEach call that you send to a model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Experiment with different parameter values to get the best values for the task. The parameters available for different models may differ. The most common parameters are the following:\\n\\n*   Max output tokens\\n*   Temperature\\n*   Top-K\\n*   Top-P\\n\\n## Prompt iteration strategies\\n\\nPrompt design is an iterative process that often requires a few iterations before you get the desired response consistently. This section provides guidance on some things you can try when iterating on your prompts.\\n\\n### Use different phrasing\\n\\nUsing different words or phrasing in your prompts often yields different responses from the model even though they all mean the same thing. If you're not getting the expected results from your prompt, try rephrasing it.\\n\\nVersion 1:\\nHow do I bake a pie?\\n\\nVersion 2:\\nSuggest a recipe for a pie.\\n\\nVersion 3:\\nWhat's a good pie recipe?\\n  \\n### Switch to an analogous task\\n\\nIf you can't get the model to follow your instructions for a task, try giving it instructions for an analogous task that achieves the same result.\\n\\nThis prompt tells the model to categorize a book by using predefined categories.\\n\\n**Prompt:**\\n\\nWhich category does The Odyssey belong to:\\nthriller\\nsci-fi\\nmythology\\nbiography\\n  \\n\\n**Response:**\\n\\n    The Odyssey belongs to the category of \\\\*\\\\*mythology\\\\*\\\\*. \\n\\n    Here's why:\\n    \\n    \\\\* \\\\*\\\\*Mythology:\\\\*\\\\* The Odyssey tells the story of Odysseus, a hero from Greek mythology, and his\\n    journey home after the Trojan War. It features gods, monsters, and supernatural events common to\\n    Greek mythology.\\n\\nThe response is correct, but the model didn't stay within the bounds of the options. You also want to model to just respond with one of the options instead of in a full sentence. In this case, you can rephrase the instructions as a multiple choice question and ask the model to choose an option.\\n\\n**Prompt:**\\n\\nMultiple choice problem: Which of the following options describes the book The Odyssey?\\nOptions:\\n- thriller\\n- sci-fi\\n- mythology\\n- biography\\n  \\n**Response:**\\n\\nThe correct answer is \\\\*\\\\*mythology\\\\*\\\\*. \\n  \\n### Change the order of prompt content\\n\\nThe order of the content in the prompt can sometimes affect the response. Try changing the content order and see how that affects the response.\\n\\nVersion 1:\\n\\\\[examples\\\\]\\n\\\\[context\\\\]\\n\\\\[input\\\\]\\n\\nVersion 2:\\n\\\\[input\\\\]\\n\\\\[examples\\\\]\\n\\\\[context\\\\]\\n\\nVersion 3:\\n\\\\[examples\\\\]\\n\\\\[input\\\\]\\n\\\\[context\\\\]\\n\\n## Fallback responses\\n\\nA fallback response is a response returned by the model when either the prompt or the response triggers a safety filter. An example of a fallback response is \\\"I'm not able to help with that, as I'm only a language model.\\\"\\n\\nIf the model responds with a fallback response, try increasing the temperature.\\n\\n## Things to avoid\\n\\n*   Avoid relying on models to generate factual information.\\n*   Use with care on math and logic problems.\\n=== Dotprompt Template Format Documentation ===\\n\\nThe following is a complete reference to authoring files using the Dotprompt executable template format. This reference contains only information about the Dotprompt text format, not surrounding language or framework implementations.\\n\\n# Reference Docs (/reference)\\n\\nA Dotprompt template is made up of four parts:\\n\\n```handlebars\\n---\\n# (1) the YAML Prompt Frontmatter goes here\\noutput:\\n  schema:\\n    # (2) the Picoschema definition goes here\\n---\\n\\n{{! (3) the Handlebars Template Content goes here }}\\n```\\n\\nWhen executed, a Dotprompt template renders into (4) Common Model Interface. \\n\\n## Reference Docs\\n\\n1. **[Prompt Frontmatter](/reference/frontmatter):** Included at the start of a Dotprompt template, frontmatter includes model configuration, input/output formatList, and tooling MediaMetadata.\\n2. **[Picoschema](/reference/picoschema):** The compact, YAML-optimized schema representation used for describing structured data in a Dotprompt template.\\n3. **[Template Content](/reference/template):** The core template of the prompt, based on Handlebars and extended with GenAI-specific capabilities.\\n4. **[Common Model Interface](/reference/model):** The \\\"output\\\" of a rendered Dotprompt template, a JSON object containing the rendered messages represented by the template as well as all associated metadata and configuration.\\n# Prompt Frontmatter (/reference/frontmatter)\\n\\n\\nThe frontmatter in Dotprompt files contains metadata and configuration for the prompt. It is defined using YAML syntax at the beginning of the file, enclosed between triple dashes (`---`).\\n\\n## Structure\\n\\n```handlebars\\n---\\n# Frontmatter content goes here\\n---\\n\\nPrompt template goes here.\\n```\\n\\nAll frontmatter fields are considered optional in a given `.prompt` file, as Dotprompt implementations may provide default values for any or all of them. If no frontmatter fields need to be specified in a given file, the frontmatter may be omitted entirely and only a prompt template provided.\\n\\n## Full Example\\n\\nHere's an example of a Dotprompt frontmatter:\\n\\n```handlebars\\n---\\nname: greetingPrompt\\nvariant: formal\\nmodel: googleai/gemini-1.5-flash\\ntools: \\n  - timeOfDay\\nconfig:\\n  version: gemini-1.5-flash-latest\\n  temperature: 0.7\\n  topK: 20\\n  topP 0.8\\n  stopSequences:\\n    - STOPSTOPSTOP\\ninput:\\n  default:\\n    name: Guest\\n  schema:\\n    name: string\\n    language?: string\\noutput:\\n  format: json\\n  schema:\\n    greeting: string, the greeting to provide to the guest\\n    formalityLevel: number, the level of formality of your response\\nmetadata:\\n  customKey:\\n    customValue: 123\\n---\\n```\\n\\n## Available Fields\\n\\n### `name`\\n- **Type:** `string`\\n- **Description:** The name of the prompt. If unspecified, inferred by the filename of the loaded prompt (e.g. `myPrompt.prompt` has an inferred name of `myPrompt`).\\n\\n### `variant`\\n- **Type:** `string`\\n- **Description:** The variant name for the prompt. If unspecified, inferred by the filename of the loaded prompt (e.g. `myPrompt.variant1.prompt` has inferred name of `myPrompt` and inferred variant of `variant1`).\\n\\n### `model`\\n- **Type:** `string` or `ModelArgument<Options>`\\n- **Description:** The name of the model to use for this prompt, e.g., `googleai/gemini-1.5-flash-latest`. The Dotprompt implementation is responsible for resolving a string model name to an executable model.\\n\\n### `tools`\\n- **Type:** `string[]`\\n- **Description:** Names of tools (registered in the Dotprompt implementation) to allow use of in this prompt.\\n\\n### `config`\\n- **Type:** `object`\\n- **Description:** Configuration to be passed to the model implementation as a `Map<string,any>`. The specific configuration options vary depending on the model implementation.\\n- **Common Config:** Model implementations should respect the following config properties where applicable:\\n  - `version`:\\n    - **Type:** `string`\\n    - **Description:** While `model` specifies a model \\\"family\\\" (e.g. Gemini 1.5 Flash, Claude 3.5 Sonnet), `version` specifies a particular version/checkpoint of the model to use. This allows for version pinning and reproducibility of results.\\n    - **Example:**  `\\\"gemini-1.5-pro-0801\\\"` or `\\\"v2\\\"`\\n\\n  - `temperature`:\\n    - **Type:** `number`\\n    - **Description:** Controls the randomness of the model's output. Higher values (e.g., `0.8`) make the output more random, while lower values (e.g., `0.2`) make it more deterministic.\\n    - **Range:** Typically between 0 and 1, depends on model implementation.\\n    - **Example:**  `0.7`\\n\\n  - `maxOutputTokens`:\\n    - **Type:** `number`\\n    - **Description:** Limits the maximum number of tokens in the model's response. This can help control the length of the generated text.\\n    - **Example:**  `150`\\n\\n  - `topK`:\\n    - **Type:** `number`\\n    - **Description:** Limits the number of highest probability vocabulary tokens to consider at each step. This can help focus the model's output on more likely tokens.\\n    - **Example:**  `40`\\n\\n  - `topP`:\\n    - **Type:** `number`\\n    - **Description:** Sets a probability threshold for token selection. The model will only consider tokens whose cumulative probability exceeds this threshold.\\n    - **Range:** Typically between 0 and 1\\n    - **Example:**  `0.95`\\n\\n  - `stopSequences`:\\n    - **Type:** `string[]`\\n    - **Description:** An array of strings that, if encountered, will cause the model to stop generating further output. This is useful for controlling where the model's response should end.\\n    - **Example:**  `[\\\"END\\\", \\\"\\\\n\\\\n\\\", \\\"User:\\\"]`\\n\\n### `input`\\n- **Type:** `object`\\n- **Description:** Defines the input variables the prompt. If `input` is not specified, the implementation should accept any `Map<string,any>` values as input and pass them to the prompt template.\\n- **Properties:**\\n  - `default`:\\n    - **Type:** `any`\\n    - **Description:** Defines the default input variable values to use if none are provided. Input values passed from the implementation should be merged into these values with a shallow merge strategy.\\n  - `schema`:\\n    - **Type:** [Schema](schema)\\n    - **Description:** Schema representing the input values for the prompt. Must correspond to a JSON Schema `object` type.\\n\\n### `output`\\n- **Type:** `object`\\n- **Description:** Defines the expected model output format.\\n- **Properties:**\\n  - `format`:\\n    - **Type:** `string`\\n    - **Common Values:** `json`, `text`\\n    - **Description:** Desired output format for this prompt. Output formats are implementation-specific, but \\n  - `schema`:\\n    - **Type:** [Schema](schema)\\n    - **Description:** Schema representing the expected output from the prompt. Must correspond to a JSON Schema `object` type.\\n\\n### `metadata`\\n- **Type:** `Map<string, any>`\\n- **Description:** Arbitrary metadata to be used by code, tools, and libraries.\\n\\n## Frontmatter Extensions\\n\\nIn the frontmatter, Dotprompt implementations will automatically collect namespaced fields (i.e. fields with a `.` in them) into a special `ext` property on the resulting metadata. For example, the following frontmatter:\\n\\n```handlebars\\n---\\nconfig:\\n  temperature: 3\\nmycorp.auth:\\n  type: FIREBASE\\n  role: admin # only admins can use this\\nmycorp.ownerId: 12345\\nmycorp.subunit.level: 5\\n---\\n```\\n\\nWould be parsed into this equivalent metadata:\\n\\n```js\\n{\\n  config: {temperature: 3},\\n  ext: {\\n    mycorp: {\\n      auth: {\\n        type: 'FIREBASE',\\n        role: 'admin',\\n      },\\n      ownerId: 12345,\\n    },\\n    'mycorp.subunit': {\\n      level: 5,\\n    },\\n  }\\n}\\n```\\n\\nNote that nested namespaces are flattened into dotted keys to avoid conflicts between nested properties and nested namespaces.# Picoschema (/reference/picoschema)\\n\\n\\nPicoschema is a compact, YAML-optimized schema definition format specifically designed to aid in describing structured data for better understanding by GenAI models. Whenever a schema is accepted by Dotprompt in its Frontmatter, the Picoschema format is accepted.\\n\\nPicoschema compiles to JSON Schema and is a subset of JSON Schema capabilities.\\n\\n## Full Example\\n\\n```yaml\\nproduct:\\n  id: string, Unique identifier for the product\\n  description?: string, Optional detailed description of the product\\n  price: number, Current price of the product\\n  inStock: integer, Number of items in stock\\n  isActive: boolean, Whether the product is currently available\\n  category(enum, Main category of the product): [ELECTRONICS, CLOTHING, BOOKS, HOME]\\n  tags(array, List of tags associated with the product): string\\n  primaryImage:\\n    url: string, URL of the primary product image\\n    altText: string, Alternative text for the image\\n  attributes(object, Custom attributes of the product):\\n    (*): any, Allow any attribute name with any value\\n  variants?(array, List of product variant objects):\\n    id: string, Unique identifier for the variant\\n    name: string, Name of the variant\\n    price: number, Price of the variant\\n```\\n\\n## Picoschema Reference\\n\\n### Basic Types\\n\\nPicoschema supports the following scalar types:\\n\\n#### **string**\\n- **Syntax:** `fieldName: string[, optional description]`\\n- **Description:** Represents a string value.\\n- **Example:** `title: string`\\n\\n#### **number**\\n- **Syntax:** `fieldName: number[, optional description]`\\n- **Description:** Represents a numeric value (integer or float).\\n- **Example:** `price: number`\\n\\n#### **integer**\\n- **Syntax:** `fieldName: integer[, optional description]`\\n- **Description:** Represents an integer value.\\n- **Example:** `age: integer`\\n\\n#### **boolean**\\n- **Syntax:** `fieldName: boolean[, optional description]`\\n- **Description:** Represents a boolean value.\\n- **Example:** `isActive: boolean`\\n\\n#### **null**\\n- **Syntax:** `fieldName: null[, optional description]`\\n- **Description:** Represents a null value.\\n- **Example:** `emptyField: null`\\n\\n#### **any**\\n- **Syntax:** `fieldName: any[, optional description]`\\n- **Description:** Represents a value of any type.\\n- **Example:** `data: any`\\n\\n### Optional Fields\\n\\n- **Syntax:** Add `?` after the field name.\\n- **Description:** Marks a field as optional. Optional fields are also automatically nullable.\\n- **Example:** `subtitle?: string`\\n\\n### Field Descriptions\\n\\n- **Syntax:** Add a comma followed by the description after the type.\\n- **Description:** Provides additional information about the field.\\n- **Example:** `date: string, the date of publication e.g. '2024-04-09'`\\n\\n### Arrays\\n\\n- **Syntax:** `fieldName(array[, optional description]): elementType`\\n- **Description:** Defines an array of a specific type.\\n- **Example:** `tags(array, string list of tags): string`\\n\\n### Objects\\n\\n- **Syntax:** `fieldName(object[, optional description]):`\\n- **Description:** Defines a nested object structure.\\n- **Example:**\\n  ```yaml\\n  address(object, the address of the recipient):\\n    address1: string, street address\\n    address2?: string, optional apartment/unit number etc.\\n    city: string\\n    state: string\\n  ```\\n\\n### Enums\\n\\n- **Syntax:** `fieldName(enum[, optional description]): [VALUE1, VALUE2, ...]`\\n- **Description:** Defines a field with a fixed set of possible values.\\n- **Example:** `status(enum): [PENDING, APPROVED, REJECTED]`\\n\\n### Wildcard Fields\\n\\n- **Syntax:** `(*): type[, optional description]`\\n- **Description:** Allows additional properties of a specified type in an object.\\n- **Example:** `(*): string`\\n\\n### Additional Notes\\n\\n1. By default, all fields are required unless marked as optional with `?`.\\n2. Objects defined using Picoschema do not allow additional properties unless a wildcard `(*)` is added.\\n3. Optional fields are automatically made nullable in the resulting JSON Schema.\\n4. The `any` type results in an empty schema `{}` in JSON Schema, allowing any value.\\n\\n## Eject to JSON Schema\\n\\nPicoschema automatically detects if a schema is already in JSON Schema format. If the top-level schema contains a `type` property with values like \\\"object\\\", \\\"array\\\", or any of the scalar types, it's treated as JSON Schema.\\n\\nYou can also explicitly use JSON Schema by defining `{\\\"type\\\": \\\"object\\\"}` at the top level. For example:\\n\\n```handlebars\\n---\\noutput:\\n  schema:\\n    type: object # this is now JSON Schema\\n    properties:\\n      field1: {type: string, description: A sample field}\\n---\\n```\\n\\n## Error Handling\\n\\nPicoschema will throw errors in the following cases:\\n1. If an unsupported scalar type is used.\\n2. If the schema contains values that are neither objects nor strings.\\n3. If parenthetical types other than 'object' or 'array' are used (except for 'enum').\\n\\nThese error checks ensure that the Picoschema is well-formed and can be correctly translated to JSON Schema.# Template Content (/reference/template)\\n\\n\\nDotprompt uses a template syntax based on [Handlebars](https://handlebarsjs.com/guide/), the popular templating language with existing implementations in several programming languages. This syntax allows for dynamic content insertion and basic logic within prompts.\\n\\n## Language Basics\\n\\nAll Dotprompt implementations **MUST** implement the Handlebars features specified in these docs, but **MAY** also implement additional capabilities as documented in the [Handlebars language specification](https://handlebarsjs.com/guide/expressions.html).\\n\\n### Expressions\\n\\nHandlebars expressions are contained within `{{}}` tags.\\n\\n#### Variable Interpolation\\n\\n- **Syntax:** `{{variableName}}` or `{{object.propertyName}}`\\n- **Description:** Inserts the value of the specified variable.\\n- **Example:** `Hello, {{name}} from {{address.city}}!`\\n\\n#### Escaped Expressions\\n\\n- **Syntax:** `\\\\` (escaped expression), `{{{variableName}}}`\\n- **Description:** Renders the literal text `{{variableName}}` without interpolation.\\n- **Example:** `This is how you show a variable: \\\\`\\n\\n## Built-in Helpers\\n\\nDotprompt provides several built-in helpers to enhance template functionality.\\n\\n### Conditional Blocks\\n\\n#### `#if`\\n\\n- **Syntax:** `{{#if condition}}...{{/if}}`\\n- **Description:** Renders the block if the condition is truthy.\\n- **Example:**\\n  ```handlebars\\n  {{#if isLoggedIn}}\\n    Welcome back!\\n  {{/if}}\\n  ```\\n\\n#### `else`\\n\\n- **Syntax:** `{{#if condition}}...{{else}}...{{/if}}`\\n- **Description:** Provides an alternative block to render if the condition is falsy.\\n- **Example:**\\n  ```handlebars\\n  {{#if isLoggedIn}}\\n    Welcome back!\\n  {{else}}\\n    Please log in.\\n  {{/if}}\\n  ```\\n\\n#### `#unless`\\n\\n- **Syntax:** `{{#unless condition}}...{{/unless}}`\\n- **Description:** Renders the block if the condition is falsy.\\n- **Example:**\\n  ```handlebars\\n  {{#unless isLoggedIn}}\\n    Please log in to continue.\\n  {{/unless}}\\n  ```\\n\\n### Iteration\\n\\n#### `#each`\\n\\n- **Syntax:** `{{#each array}}...{{/each}}`\\n- **Description:** Iterates over an array or object properties, assigning `this` to the currently enumerated item and `@index` to the index or key within the array or object.\\n- **Example:**\\n  ```handlebars\\n  {{#each items}}\\n    - {{this}} is item {{@index}}\\n  {{/each}}\\n  ```\\n\\n## Dotprompt Helpers\\n\\nThe following helpers **MUST** be included in all implementations of Dotprompt and provide the tools to manage multi-message and multi-modal prompting.\\n\\n#### `json`\\n\\n- **Syntax:** `{{json varName}}`\\n- **Description:** Serializes the provided variable into JSON and inserts it at the expression point.\\n- **Example:**\\n  ```handlebars\\n  Here is information about the current user:\\n\\n  {{ json currentUser }}\\n  ```\\n\\n#### `role`\\n\\n- **Syntax:** `{{role \\\"roleName\\\"}}`\\n- **Description:** Begins a new message with the specified role for multi-message prompts.\\n- **Example:**\\n  ```handlebars\\n  {{role \\\"system\\\"}}\\n  You are a helpful AI assistant.\\n  {{role \\\"user\\\"}}\\n  What's the weather like today?\\n  ```\\n\\n#### `history`\\n\\n- **Syntax:** `{{history}}`\\n- **Description:** Inserts the conversation history (passed as `messages` when rendering the template) for multi-turn prompts.\\n- **Example:**\\n  ```handlebars\\n  {{role \\\"system\\\"}}\\n  You are a helpful AI assistant.\\n  {{history}}\\n  {{role \\\"user\\\"}}\\n  What was my last question about?\\n  ```\\n\\n#### `media`\\n\\n- **Syntax:** `{{media url=urlVariable}}`\\n- **Description:** Inserts media content (e.g., images) into the prompt.\\n- **Example:**\\n  ```handlebars\\n  Describe this image:\\n  {{media url=imageUrl}}\\n  ```\\n\\n#### `section`\\n\\n- **Syntax:** `{{section \\\"sectionName\\\"}}`\\n- **Description:** Manually positions specific sections within the prompt.\\n- **Example:**\\n  ```handlebars\\n  This is the main content.\\n\\n  {{section \\\"output\\\"}}\\n\\n  This comes after the output instructions.\\n  ```\\n\\n## Partials\\n\\nPartials are reusable template snippets that can be included in other templates.\\n\\n- **Syntax:** `{{>partialName}}`\\n- **Description:** Includes the content of the specified partial.\\n- **Example:**\\n  ```handlebars\\n  {{>header}}\\n  Main content goes here.\\n  {{>footer}}\\n  ```\\n\\n### Partial with Arguments\\n\\n- **Syntax:** `{{>partialName arg1=value1 arg2=value2}}`\\n- **Description:** Includes a partial with specific arguments.\\n- **Example:**\\n  ```handlebars\\n  {{>greeting name=userName style=greetingStyle}}\\n  ```\\n\\n### Partial with Context\\n\\n- **Syntax:** `{{>partialName this}}`\\n- **Description:** Passes the current context to the partial.\\n- **Example:**\\n  ```handlebars\\n  {{#each items}}\\n    {{>listItem this}}\\n  {{/each}}\\n  ```\\n\\n## Custom Helpers\\n\\nAll Dotprompt implementations **MUST** allow for the definition of custom helpers to extend Dotprompt syntax. The specific mechanism of custom helper registration is up to the specific implementation. Custom helpers are used in the following manner:\\n\\n- **Basic Custom Helper:** `{{customHelperName arg1 \\\"arg2\\\"}}`\\n- **Named Arguments:** `{{customHelperName arg1=var1 arg2=\\\"var2\\\"}}`\\n\\n## Context Variables\\n\\nWhen rendering a template, additional contextual information is provided as variables with a special `@` prefix. Some of these are built-in:\\n\\n- `@root`: references the root variable context regardless of current `this`\\n- `@first`: `true` when iterating the first item of an `#each` block.\\n- `@last`: `true` when iterating the last item of an `#each` block.\\n- `@key`: key name for the current iteration of an `#each` block.\\n- `@metadata`: provides access to metadata of the currently running prompt and passed in data arguments.\\n  - `@metadata.prompt`: access to the frontmatter configuration of the current prompt.\\n  - `@metadata.docs`: access to the passed in document context of the current execution.\\n  - `@metadata.messages`: access to the message history of the current execution.\\n\\nIn addition to the above context variables, you can provide a `context` argument when rendering a template to add additional contextual information. for example, a context argument of `{state: {name: 'Evelyn'}, isAdmin: true}` would create `@state` and `@isAdmin` variables accessible from inside the prompt.# Common Model Interface (/reference/model)\\n\\n\\nDotprompt implementations are not required to conform to any specific structured interface for interacting with GenAI models. However, the Dotprompt reference implementation in [Firebase Genkit](https://github.com/firebase/genkit) leverages a common model interface that may be useful for other implementors to follow.\\n\\nIn the future, a Dotprompt \\\"spec test\\\" will be made available that exercises the various parts of Dotprompt and compares the results to this common model request format.\\n\\n## GenerateRequest\\n\\n### Full Example\\n\\n```json\\n{\\n  \\\"messages\\\": [\\n    {\\n      \\\"role\\\": \\\"system\\\",\\n      \\\"content\\\": [\\n        {\\\"text\\\": \\\"You are a helpful AI assistant.\\\"}\\n      ]\\n    },\\n    {\\n      \\\"role\\\": \\\"user\\\",\\n      \\\"content\\\": [\\n        {\\\"text\\\": \\\"Hello, can you help me with a task?\\\"}\\n      ]\\n    },\\n    {\\n      \\\"role\\\": \\\"model\\\",\\n      \\\"content\\\": [\\n        {\\\"text\\\": \\\"Of course! I'd be happy to help you with a task. What kind of task do you need assistance with? Please provide me with more details, and I'll do my best to help you.\\\"}\\n      ]\\n    },\\n    {\\n      \\\"role\\\": \\\"user\\\",\\n      \\\"content\\\": [\\n        {\\\"text\\\": \\\"Can you analyze this image and tell me what you see?\\\"},\\n        {\\n          \\\"media\\\": {\\n            \\\"contentType\\\": \\\"image/jpeg\\\",\\n            \\\"url\\\": \\\"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAMCAg...\\\"\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"config\\\": {\\n    \\\"temperature\\\": 0.7,\\n    \\\"maxOutputTokens\\\": 1000,\\n    \\\"topK\\\": 40,\\n    \\\"topP\\\": 0.95,\\n    \\\"stopSequences\\\": [\\\"User:\\\", \\\"Human:\\\"]\\n  },\\n  \\\"tools\\\": [\\n    {\\n      \\\"name\\\": \\\"weather\\\",\\n      \\\"description\\\": \\\"Get the current weather for a location\\\",\\n      \\\"inputSchema\\\": {\\n        \\\"type\\\": \\\"object\\\",\\n        \\\"properties\\\": {\\n          \\\"location\\\": {\\n            \\\"type\\\": \\\"string\\\",\\n            \\\"description\\\": \\\"The location to get weather for\\\"\\n          }\\n        },\\n        \\\"required\\\": [\\\"location\\\"]\\n      },\\n      \\\"outputSchema\\\": {\\n        \\\"type\\\": \\\"object\\\",\\n        \\\"properties\\\": {\\n          \\\"temperature\\\": {\\n            \\\"type\\\": \\\"number\\\",\\n            \\\"description\\\": \\\"The current temperature in Celsius\\\"\\n          },\\n          \\\"condition\\\": {\\n            \\\"type\\\": \\\"string\\\",\\n            \\\"description\\\": \\\"The current weather condition\\\"\\n          }\\n        },\\n        \\\"required\\\": [\\\"temperature\\\", \\\"condition\\\"]\\n      }\\n    }\\n  ],\\n  \\\"output\\\": {\\n    \\\"format\\\": \\\"json\\\",\\n    \\\"schema\\\": {\\n      \\\"type\\\": \\\"object\\\",\\n      \\\"properties\\\": {\\n        \\\"analysis\\\": {\\n          \\\"type\\\": \\\"string\\\",\\n          \\\"description\\\": \\\"A detailed analysis of the image\\\"\\n        },\\n        \\\"objects\\\": {\\n          \\\"type\\\": \\\"array\\\",\\n          \\\"items\\\": {\\n            \\\"type\\\": \\\"string\\\"\\n          },\\n          \\\"description\\\": \\\"A list of objects identified in the image\\\"\\n        }\\n      },\\n      \\\"required\\\": [\\\"analysis\\\", \\\"objects\\\"]\\n    }\\n  },\\n  \\\"context\\\": [\\n    {\\n      \\\"id\\\": \\\"doc1\\\",\\n      \\\"content\\\": [{\\\"text\\\": \\\"This is some context information that might be relevant to the task.\\\"}],\\n      \\\"metadata\\\": {\\n        \\\"source\\\": \\\"user-provided\\\"\\n      }\\n    }\\n  ]\\n}\\n```\\n### Properties\\n\\n#### `messages`\\n- **Type:** `array` of [Message](#message) objects.\\n- **Description:** The conversation history and current prompt.\\n\\n#### `config`\\n- **Type:** [ModelConfig](#modelconfig)\\n- **Description:** Configuration options for the model.\\n\\n#### `tools`\\n- **Type:** `array` of [ToolDefinition](#tooldefinition)\\n- **Description:** Definitions of tools available to the model.\\n\\n#### `output`\\n- **Type:** [Output](#output)\\n- **Description:** Specification for the desired output format.\\n\\n#### `context`\\n- **Type:** `array` of [Document](#document)\\n- **Description:** Grounding context documents for the model.\\n\\n## Message\\n\\nA message represents a single \\\"turn\\\" in a multi-turn conversation. Each message must have a role and specified content.\\n\\n### Properties\\n\\n#### `role`\\n- **Type:** `string`\\n- **Description:** The role of the message sender. Can be \\\"system\\\", \\\"user\\\", \\\"model\\\", or \\\"tool\\\".\\n\\n#### `content`\\n- **Type:** `array` of [Part](#part)\\n- **Description:** The content of the message, which can include text, media, tool requests, and tool responses.\\n\\n#### `metadata`\\n- **Type:** `object`\\n- **Description:** Optional. Additional metadata for the message.\\n\\n## Part\\n\\nA `Part` object can be one of the following types:\\n\\n### TextPart\\n\\n#### `text`\\n- **Type:** `string`\\n- **Description:** The text content of the message.\\n\\n### MediaPart\\n\\n#### `media`\\n- **Type:** `object`\\n- **Description:** Contains media information.\\n\\n#### `media.contentType`\\n- **Type:** `string`\\n- **Description:** Optional. The media content type. Inferred from data URI if not provided.\\n\\n#### `media.url`\\n- **Type:** `string`\\n- **Description:** A `data:` or `https:` URI containing the media content.\\n\\n### ToolRequestPart\\n\\n#### `toolRequest`\\n- **Type:** `object`\\n- **Description:** A request for a tool to be executed.\\n\\n#### `toolRequest.ref`\\n- **Type:** `string`\\n- **Description:** Optional. The call ID or reference for a specific request.\\n\\n#### `toolRequest.name`\\n- **Type:** `string`\\n- **Description:** The name of the tool to call.\\n\\n#### `toolRequest.input`\\n- **Type:** `any`\\n- **Description:** Optional. The input parameters for the tool, usually a JSON object.\\n\\n### ToolResponsePart\\n\\n#### `toolResponse`\\n- **Type:** `object`\\n- **Description:** A provided response to a tool call.\\n\\n#### `toolResponse.ref`\\n- **Type:** `string`\\n- **Description:** Optional. The call ID or reference for a specific request.\\n\\n#### `toolResponse.name`\\n- **Type:** `string`\\n- **Description:** The name of the tool.\\n\\n#### `toolResponse.output`\\n- **Type:** `any`\\n- **Description:** Optional. The output data returned from the tool, usually a JSON object.\\n\\n## ModelConfig\\n\\n`ModelConfig` is an arbitrary `Map<string,any>` that depends on the specific implementation of the underlying model. However, the following common configuration options should be respected in implementation whenever applicable:\\n\\n### Common Config Properties\\n#### `temperature`\\n- **Type:** `number`\\n- **Description:** Optional. Controls the randomness of the model's output.\\n\\n#### `maxOutputTokens`\\n- **Type:** `number`\\n- **Description:** Optional. Limits the maximum number of tokens in the model's response.\\n\\n#### `topK`\\n- **Type:** `number`\\n- **Description:** Optional. Limits the number of highest probability vocabulary tokens to consider at each step.\\n\\n#### `topP`\\n- **Type:** `number`\\n- **Description:** Optional. Sets a probability threshold for token selection.\\n\\n#### `stopSequences`\\n- **Type:** `array` of `string`\\n- **Description:** Optional. Sequences that, if encountered, will cause the model to stop generating further output.\\n\\n## Tool Object\\n\\n### `name`\\n- **Type:** `string`\\n- **Description:** The name of the tool.\\n\\n### `description`\\n- **Type:** `string`\\n- **Description:** A description of what the tool does.\\n\\n### `inputSchema`\\n- **Type:** `object`\\n- **Description:** A JSON Schema object describing the expected input for the tool.\\n\\n### `outputSchema`\\n- **Type:** `object`\\n- **Description:** Optional. A JSON Schema object describing the expected output from the tool.\\n\\n## Output Object\\n\\n### `format`\\n- **Type:** `string`\\n- **Description:** Optional. The desired output format. All implementations should support `json` and `text` at a minimum.\\n\\n### `schema`\\n- **Type:** `object`\\n- **Description:** Optional. A JSON Schema object describing the expected structure of the output.\\n\\n## Document Object\\n\\n### `id`\\n- **Type:** `string`\\n- **Description:** A unique identifier for the document.\\n\\n### `content`\\n- **Type:** `string`\\n- **Description:** The text content of the document.\\n\\n### `metadata`\\n- **Type:** `object`\\n- **Description:** Optional. Additional metadata for the document.\\n\\n## Notes\\n\\n- The `messages` array represents the conversation history and current prompt. Each message can contain multiple parts, allowing for rich, multimodal interactions.\\n- The `config` object allows fine-tuning of the model's behavior. Not all models support all configuration options.\\n- The `tools` array defines functions that the model can call during its execution. This enables the model to interact with external systems or perform specific tasks.\\n- The `output` object specifies the desired format and structure of the model's response. This is particularly useful for ensuring consistent, parseable outputs.\\n- The `context` array provides additional information that may be relevant to the task but isn't part of the direct conversation history.\\n- The `candidates` field determines how many alternative responses the model should generate.\\n\\nThis interface provides a flexible and powerful way to interact with GenAI models, supporting various types of inputs, outputs, and model configurations.\\n=== Task Recap ===\\n\\nYou are generating the source code for a Dotprompt LLM prompt based on the user's request and the documentation you've been provided. Generate ONLY the source, no explanation.\"}]}],\"config\":{\"temperature\":0.4,\"topK\":32,\"topP\":0.95},\"tools\":[]}","genkit:output":"{\"candidates\":[{\"index\":0,\"message\":{\"role\":\"model\",\"content\":[{\"text\":\"```handlebars\\n---\\nname: recipeGenerator\\ninput:\\n  schema:\\n    cuisine?: string, the type of cuisine for the recipe (e.g., Italian, Mexican, Indian)\\n    dishType?: string, the type of dish (e.g., appetizer, main course, dessert)\\n    ingredients?: string, comma-separated list of ingredients to include\\n    dietaryRestrictions?: string, dietary restrictions (e.g., vegetarian, vegan, gluten-free)\\noutput:\\n  format: json\\n  schema:\\n    title: string, the title of the recipe\\n    description: string, a brief description of the recipe\\n    cuisine: string, the cuisine of the recipe\\n    dishType: string, the type of dish\\n    ingredients(array, list of ingredients):\\n      name: string, the name of the ingredient\\n      quantity: string, the quantity of the ingredient\\n    instructions(array, list of instructions): string\\n    prepTime: string, the preparation time\\n    cookTime: string, the cooking time\\n    totalTime: string, the total time to make the recipe\\n    servings: string, the number of servings the recipe makes\\n---\\n\\n{{role \\\"system\\\"}}\\nYou are a recipe generator. You will generate a delicious recipe based on the user's request.\\n\\n{{role \\\"user\\\"}}\\nGenerate a recipe.\\n{% if cuisine %}\\nCuisine: {{cuisine}}\\n{% endif %}\\n{% if dishType %}\\nDish Type: {{dishType}}\\n{% endif %}\\n{% if ingredients %}\\nIngredients: {{ingredients}}\\n{% endif %}\\n{% if dietaryRestrictions %}\\nDietary Restrictions: {{dietaryRestrictions}}\\n{% endif %}\\n```\"}]},\"finishReason\":\"stop\",\"custom\":{}}],\"custom\":{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"```handlebars\\n---\\nname: recipeGenerator\\ninput:\\n  schema:\\n    cuisine?: string, the type of cuisine for the recipe (e.g., Italian, Mexican, Indian)\\n    dishType?: string, the type of dish (e.g., appetizer, main course, dessert)\\n    ingredients?: string, comma-separated list of ingredients to include\\n    dietaryRestrictions?: string, dietary restrictions (e.g., vegetarian, vegan, gluten-free)\\noutput:\\n  format: json\\n  schema:\\n    title: string, the title of the recipe\\n    description: string, a brief description of the recipe\\n    cuisine: string, the cuisine of the recipe\\n    dishType: string, the type of dish\\n    ingredients(array, list of ingredients):\\n      name: string, the name of the ingredient\\n      quantity: string, the quantity of the ingredient\\n    instructions(array, list of instructions): string\\n    prepTime: string, the preparation time\\n    cookTime: string, the cooking time\\n    totalTime: string, the total time to make the recipe\\n    servings: string, the number of servings the recipe makes\\n---\\n\\n{{role \\\"system\\\"}}\\nYou are a recipe generator. You will generate a delicious recipe based on the user's request.\\n\\n{{role \\\"user\\\"}}\\nGenerate a recipe.\\n{% if cuisine %}\\nCuisine: {{cuisine}}\\n{% endif %}\\n{% if dishType %}\\nDish Type: {{dishType}}\\n{% endif %}\\n{% if ingredients %}\\nIngredients: {{ingredients}}\\n{% endif %}\\n{% if dietaryRestrictions %}\\nDietary Restrictions: {{dietaryRestrictions}}\\n{% endif %}\\n```\"}],\"role\":\"model\"},\"finishReason\":\"STOP\",\"avgLogprobs\":-0.07430766673570269}],\"usageMetadata\":{\"promptTokenCount\":12331,\"candidatesTokenCount\":356,\"totalTokenCount\":12687,\"promptTokensDetails\":[{\"modality\":\"TEXT\",\"tokenCount\":12331}],\"candidatesTokensDetails\":[{\"modality\":\"TEXT\",\"tokenCount\":356}]},\"modelVersion\":\"gemini-2.0-flash\"},\"usage\":{\"inputCharacters\":52583,\"inputImages\":0,\"inputVideos\":0,\"inputAudioFiles\":0,\"outputCharacters\":1426,\"outputImages\":0,\"outputVideos\":0,\"outputAudioFiles\":0,\"inputTokens\":12331,\"outputTokens\":356,\"totalTokens\":12687},\"latencyMs\":2974.722084000008}","genkit:state":"success"},"displayName":"googleai/gemini-2.0-flash","links":[],"spanKind":"INTERNAL","sameProcessAsParentSpan":{"value":true},"status":{"code":0},"timeEvents":{"timeEvent":[]},"instrumentationLibrary":{"name":"genkit-tracer","version":"v1"}}},"displayName":"googleai/gemini-2.0-flash","startTime":1740766011571,"endTime":1740766014549.2598}